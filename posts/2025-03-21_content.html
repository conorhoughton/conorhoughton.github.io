<p><b>(2025-02-26)</b> New paper to appear in CHI2025 Late-Breaking Work.</p>
<p><b>Can LLMs be used to quantify the emotional salience of text statements using an Elo rating system?</b><br>
Kimberley Beaumont, Martin Oravec, Harry Emerson, Ian Penton-Voak and Conor Houghton<br>
<a href="https://osf.io/preprints/psyarxiv/qsn4b">psyarxiv/qsn4b</a></p>
<p>Over the last few years as part of our experiments we have asked a
over a thousand participants <i>Is an event or experience (either
positive or negative) significantly affecting your mood right now?</i>
and if they said yes, we asked them to write down what that event was
and to rate how negative or positive the event was using a slider on a
  scale of zero to 100.</p>

<p>We ended up with a large collection of events, after cleaning, 363
in all. The most positive were very positive, with one
reporting <i>mindblowing sex</i> and another a marraige proposal; the
most negative are awful. Ultimately one of things we are interested in
is the difference between short and long term mood or affective state
and, in addition to the events we have mood questionaire date. To
relate the two we need a numerical quantification for how negative or
positive the events are; of course, we do have the participants own
rating, but that may reflect there mood rather than the degree to
  which the event they mention is actually negative or positive.</p>

<p>To get a score for the events we decided to use an Elo system. We
recruits another set of online participant and asked them to compare
pairs of statements and say which was the more negative, or more
positive; the question varied. Out of these pairwise comparisons we
created a score using the Elo system designed for chess. The graph
below shows how the score changes as comparisons are made; some events
go up, some stay the same, some go down. The initial score is scaled
but is determined by the original rating supplied by the participant
reporting the event; nonetheless, the comparisons lead to them
diverging.</p>

<p><img src="../images/2025-03-21_Elo_Human.png" alt="A graph shows a
group of lines that start in the same place at the left but diverge in
what looks like a series of directed random walks as you move right
along the x-axis, which is labelled comparison number; the y-axis is
labelled Elo-Value, three lines are picked out in colour, one goes up,
one stays the same, one goes down" width="500px"></p>

<p>In the way, we now have quanitative scores for the individual events
are we are examinging the relationship between these scores and the
results of the mood questionaires. This is on-going. However, in the
meantime we were curious as to whether LLMs would perform well on this
task; if they performed the comparisons would they give a similar set
of scores to the humans. This is interesting in two ways, first,
recruiting participants to do the comparisons is slow and expensive,
if LLMs are equally good at the task, this could make it easier to use
Elo rankings to score the emotional valence and salience of text
statements. Second, it is interesting to see how well an LLM can
assess these statements since success would indicate that the LLMs can
  enact a simulation of what might be called emotional intelligence.</p>

<p>Of course, it turns out the LLMs are extremely good at this task,
the graph bellow plots the result of human rating and rating by
GPT-3.5-Turbo; with the points colored according to the original
score, determined by the self-reported score.</p>


<p><img src="../images/2025-03-21_Elo_Human.png" alt="A graph shows a
group of lines that start in the same place at the left but diverge in
what looks like a series of directed random walks as you move right
along the x-axis, which is labelled comparison number; the y-axis is
labelled Elo-Value, three lines are picked out in colour, one goes up,
one stays the same, one goes down" width="500px"></p>



